z_hat = alpha %*% v_try  # locations in R^2
points(z_hat, col='blue', pch=4)
segments(0, 0, v_try[1], v_try[2], col='red', lwd=4)
hist(alpha, 25, xlim=c(-3,3), main=round(var(alpha), 2))
countdata = read.csv("../data/congress109.csv", header=TRUE, row.names=1)
memberdata = read.csv("../data/congress109members.csv", header=TRUE, row.names=1)
# Normalize phrase counts to phrase frequencies
Z = countdata/rowSums(countdata)
# PCA
pc2 = prcomp(Z, scale=TRUE)
loadings = pc2$rotation
scores = pc2$x
qplot(scores[,1], scores[,2], color=memberdata$party, xlab='Component 1', ylab='Component 2')
install.packages('ggplot2')
qplot(scores[,1], scores[,2], color=memberdata$party, xlab='Component 1', ylab='Component 2')
library(ggplot2)
qplot(scores[,1], scores[,2], color=memberdata$party, xlab='Component 1', ylab='Component 2')
# The top words associated with each component
o1 = order(loadings[,1])
colnames(Z)[head(o1,25)]
colnames(Z)[tail(o1,25)]
setwd("~")
rm(list=ls())
clear()
setwd("R/STA380")
Votes = read.csv('georgia2000.csv', header=TRUE)
summary(Votes)
Votes$undercount = Votes$ballots - Votes$votes
summary(Votes)
pairs(Votes)
boxplot(Votes$undercount, Votes$equip)
?boxplot
boxplot(Votes$undercount ~ Votes$equip)
boxplot(undercount~equip, data=Votes)
boxplot(undercount~equip, data=Votes)
lm.fit = glm(undercount~equip, data=Votes)
summary(lm.fit)
xyplot(undercount~equip, data=Votes)
plot(undercount~equip, data=Votes)
plot(poor~equip)
plot(poor~equip, data=Votes)
lm.fit = glm(equip~poor, data=Votes)
summary(lm.fit)
scatterplot(equip, poor, data=Votes)
plot(Votes$equip, Votes$poor)
table(Votes$equip, Votes$poor)
table(equip, poor, data=Votes)
table(Votes$equip, Votes$poor, Votes$undercount)
table(Votes$equip, Votes$poor)
x = !!
x
x = table(Votes$equip, Votes$poor)
plot(x)
ftable(x)
margin.table(x, 1)
margin.table(x, 2)
prop.table(x)
xtabs(~poor+equip+undercount, data=Votes)
prop.table(x)
x
plot(x)
points(x)
lines(x)
hist(x)
xtabs(~poor + equip, data=Votes)
prop.table(xtabs(~poor + equip, data=Votes), margin=1)
relrisk(~poor + equip, data=Votes)
p1
t1 = xtabs(~poor + equip, data=Votes)
p1 = prop.table(t1, margin=1)
p1
p1[1,1]
p1[1,1]
t1
t1[4,1]
t1[1,4]
t1[1,4]/sum(t1[1,])
t1[2,4]/sum(t1[2,])
relrisk = p1[1,4]/p1[2,4]
relrisk
summary(Votes)
Votes$pctunder = Votes$undercount/Votes$ballots
table(Votes$pctunder)
summary(Votes$pctunder)
t1
p1
boxplot(pctunder~equip, data=Votes)
mean(Votes$pctunder)
relrisk = p1[1,2]/p1[2,2]
relrisk
lm.fit = lm(pctunder~perAA, data=Votes)
summary(lm.fit)
lm.fit = lm(perAA~equip, data=Votes)
summary(lm.fit)
plot(Votes$perAA, Votes$equip)
library(mosaic)
library(fImport)
library(foreach)
mystocks = c("SPY", "TLT", "LQD", "EEM", "VNQ")
myprices = yahooSeries(mystocks, from='2010-08-05', to='2015-08-05')
mystocks = c("SPY", "TLT", "LQD", "EEM", "VNQ")
myprices = yahooSeries(mystocks, from='2010-08-05', to='2015-08-05')
YahooPricesToReturns = function(series) {
mycols = grep('Adj.Close', colnames(series))
closingprice = series[,mycols]
N = nrow(closingprice)
percentreturn = as.data.frame(closingprice[2:N,]) / as.data.frame(closingprice[1:(N-1),]) - 1
mynames = strsplit(colnames(percentreturn), '.', fixed=TRUE)
mynames = lapply(mynames, function(x) return(paste0(x[1], ".PctReturn")))
colnames(percentreturn) = mynames
as.matrix(na.omit(percentreturn))
}
myreturns = YahooPricesToReturns(myprices)
pairs(myreturns)
plot(myreturns[,1], type='l')
plot(myreturns[,3], type='l')
acf(myreturns[,3])
cor(myreturns)
head(myreturns)
hist(sim1[,n_days], 25)
cor(myreturns)
totalwealth = 100000
weights1 = c(0.2, 0.2, 0.2, 0.2, 0.2)
holdings = weights1 * totalwealth
n_days = 20
sim1 = foreach(i=1:5000, .combine='rbind') %do% {
totalwealth = 100000
weights = c(0.2, 0.2, 0.2, 0.2, 0.2)
holdings = weights * totalwealth
wealthtracker = rep(0, n_days)
for(today in 1:n_days) {
return.today = resample(myreturns, 1, orig.ids=FALSE)
holdings = holdings + holdings*return.today
totalwealth = sum(holdings)
wealthtracker[today] = totalwealth
}
wealthtracker
}
head(sim1)
hist(sim1[,n_days], 25)
# Profit/loss
hist(sim1[,n_days]- 10000)
hist(sim1[,n_days]- 100000)
quantile(sim1[,n_days], 0.05) - 100000
sim1 = foreach(i=1:5000, .combine='rbind') %do% {
totalwealth = 100000
weights = c(0.2, 0.2, 0.2, 0.2, 0.2)
holdings = weights * totalwealth
wealthtracker = rep(0, n_days)
for(today in 1:n_days) {
return.today = resample(myreturns, 1, orig.ids=FALSE)
holdings = holdings + holdings*return.today
totalwealth = sum(holdings)
wealthtracker[today] = totalwealth
}
#wealthtracker
}
hist(sim1[,n_days], 25)
hist(sim1[,n_days]- 100000)
variance(myreturns)
var(myreturns)
Votes = read.csv('georgia2000.csv', header=TRUE)
Wines = read.csv('wine.csv', header=TRUE)
summary(Wines)
Wine = read.csv('wine.csv', header=TRUE)
wine_scaled = scale(Wine, center=TRUE, scale=TRUE)
wine_chem = Wine[,1:11]
wine_scaled = scale(wine_chem, center=TRUE, scale=TRUE)
summary(wine_scaled)
wine_chem = Wine[,-c("quality", "color")]
wine_chem = Wine[,- c("quality", "color")]
wine_chem = Wine[,c(-"quality", -"color")]
qc = c("quality", "color")
wine_chem = Wine[,-qc]
wine_chem = Wine[,1:11]
wine_scaled = scale(wine_chem, center=TRUE, scale=TRUE)
summary(wine_scaled)
cluster = kmeans(wine_scaled, centers = 2)
summary(cluster)
names(cluser)
names(cluster)
plot(wine_scaled[,"density"], wine_scaled[,"alcohol"], xlim=c(-2,2.75),
type="n", xlab="density", ylab="alcohol")
?qplot
cluster$centers
plot(wine_scaled[,"density"], wine_scaled[,"alcohol"], xlim=c(-2,2.75),
type="n", xlab="density", ylab="alcohol")
text(wine_scaled[,"density"], protein_scaled[,"alcohol"], labels=rownames(wine_chem),
col=rainbow(2)[cluster_redwhite$cluster])
text(wine_scaled[,"density"], wine_scaled[,"alcohol"], labels=rownames(wine_chem),
col=rainbow(2)[cluster_redwhite$cluster])
text(wine_scaled[,"density"], wine_scaled[,"alcohol"], labels=rownames(wine_chem),
col=rainbow(2)[cluster$cluster])
?text
text(wine_scaled[,"density"], wine_scaled[,"alcohol"], labels=wine$color,
col=rainbow(2)[cluster$cluster])
text(wine_scaled[,"density"], wine_scaled[,"alcohol"], labels=Wines$color,
col=rainbow(2)[cluster$cluster])
qplot(cluster_chem)
cluster_chem = kmeans(wine_scaled, centers = 2)
qplot(cluster_chem)
?qplot
plotcluster(wine_scaled, cluster_chem$cluster)
library(cluster)
plotcluster(wine_scaled, cluster_chem$cluster)
library(fpc)
install.packages('fpc')
library(fpc)
plotcluster(wine_scaled, cluster_chem$cluster)
str(cluster_chem)
str(Wine)
qplot(color, quality, data=Wine, color=factor(cluster_chem$cluster),cex= 1.2)
cluster_chem = kmeans(wine_scaled, centers = 10)
qplot(color, quality, data=Wine, color=factor(cluster_chem$cluster),cex= 1.2)
plotcluster(wine_scaled, cluster_chem$cluster)
table(Wine$color,cluster_chem$cluster)
table(Wine$quality,cluster_chem$cluster)
cluster_chem = kmeans(wine_scaled, centers = 2)
table(Wine$color,cluster_chem$cluster)
cluster_chem = kmeans(wine_scaled, centers = 2, n=50)
table(Wine$color,cluster_chem$cluster)
cluster_chem = kmeans(wine_scaled, centers = 10, n=50)
plotcluster(wine_scaled, cluster_chem$cluster)
?plotcluster
cluster_chem = kmeans(wine_scaled, centers = 2, n=50)
plotcluster(wine_scaled, cluster_chem$cluster)
summary(Wine)
qplot(color, density, data=Wine, color=factor(cluster_chem$cluster))
table(Wine$quality,cluster_chem$cluster)
table(Wine$color,cluster_chem$cluster)
pc.wine = prcomp(wine_scaled, scale=TRUE)
summary(pc.wine)
sum((pc.wine$sdev)^2)
plot(pc.wine)
biplot(pc.wine)
loadings = pc.wine$rotation
scores = pc.wine$x
head(scores)
nrow(scores)
qplot(scores[,1], scores[,2], color=pc.wine$color, xlab='Component 1', ylab='Component 2')
qplot(scores[,1], scores[,2], color=pc.wine$quality, xlab='Component 1', ylab='Component 2')
qplot(scores[,1], scores[,2], color=Wine$color, xlab='Component 1', ylab='Component 2')
qplot(scores[,1], scores[,2], color=Wine$quality, xlab='Component 1', ylab='Component 2')
qplot(scores[,1], color=wine.data$color, xlab='Component 1', ylab='Component 2')
qplot(scores[,1], color=Wine$color, xlab='Component 1', ylab='Component 2')
qplot(scores[,2], color=Wine$color, xlab='Component 1', ylab='Component 2')
o1 = order(loadings[,1])
colnames(wine_scaled)[head(o1,3)]
colnames(wine_scaled)[tail(o1,3)]
o2 = order(loadings[,2])
colnames(wine_scaled)[head(o2,3)]
colnames(wine_scaled)[tail(o2,3)]
colnames(wine_scaled)[head(o1,4)]
colnames(wine_scaled)[tail(o1,4)]
o2 = order(loadings[,2])
colnames(wine_scaled)[head(o2,4)]
colnames(wine_scaled)[tail(o2,4)]
o1 = order(loadings[,1])
colnames(wine_scaled)[head(o1,4)]
colnames(wine_scaled)[tail(o1,4)]
o2 = order(loadings[,2])
colnames(wine_scaled)[head(o2,4)]
colnames(wine_scaled)[tail(o2,4)]
twitter.data = read.csv('social_marketing.csv', header=TRUE)
summary(twitter.data)
str(twitter.data)
twitter.data = scale(twitter.data[2:37], center=TRUE, scale=TRUE)
pc.twitter = prcomp(twitter.scaled, scale=TRUE)
twitter.scaled = scale(twitter.data[2:37], center=TRUE, scale=TRUE)
pc.twitter = prcomp(twitter.scaled, scale=TRUE)
loadings = pc.wine$rotation
loadings = pc.twitter$rotation
scores = pc.twitter$x
qplot(scores[,1], scores[,2], xlab='Component 1', ylab='Component 2')
summary(pc.twitter)
summary(twitter.scaled)
twitter.scaled = scale(twitter.data[,2:37], center=TRUE, scale=TRUE)
twitter.data = read.csv('social_marketing.csv', header=TRUE)
twitter.data = twitter.data[,2:37]
twitter.scaled = scale(twitter.data[,2:37], center=TRUE, scale=TRUE)
twitter.scaled = scale(twitter.data, center=TRUE, scale=TRUE)
summary(twitter.scaled)
pc.twitter = prcomp(twitter.scaled, scale=TRUE)
loadings = pc.twitter$rotation
scores = pc.twitter$x
qplot(scores[,1], scores[,2], xlab='Component 1', ylab='Component 2')
o1 = order(loadings[,1])
colnames(wine_scaled)[head(o1,6)]
colnames(twitter.scaled)[head(o1,6)]
colnames(twitter.scaled)[tail(o1,6)]
o2 = order(loadings[,2])
colnames(twitter.scaled)[head(o2,6)]
colnames(twitter.scaled)[tail(o2,6)]
colnames(twitter.scaled)[head(o1,10)]
colnames(twitter.scaled)[tail(o1,10)]
o2 = order(loadings[,2])
colnames(twitter.scaled)[head(o2,10)]
colnames(twitter.scaled)[tail(o2,10)]
cluster_cat = kmeans(twitter.scaled, centers = 2, n=50)
#plotcluster(twitter.scaled, cluster_cat$cluster)
qplot(religion, sports_fandom, data=twitter.data, color=factor(cluster_cat$cluster))
qplot(parenting, family, data=twitter.data, color=factor(cluster_cat$cluster))
qplot(religion, sports_fandom, family, data=twitter.data, color=factor(cluster_cat$cluster))
cluster_cat = kmeans(wine_scaled, centers = 10, n=50)
qplot(religion, sports_fandom, data=twitter.data, color=factor(cluster_cat$cluster))
qplot(parenting, family, data=twitter.data, color=factor(cluster_cat$cluster))
?subset
plotcluster(wine_scaled, cluster_chem$cluster)
plotcluster(twitter.scaled, cluster_cat$cluster)
cluster_cat = kmeans(wine_scaled, centers = 10, n=50)
plot(cluster_cat)
summary(cluster_cat)
rm(list=ls())
twitter.data = read.csv('social_marketing.csv', header=TRUE)
twitter.data = twitter.data[,2:37]
twitter.scaled = scale(twitter.data, center=TRUE, scale=TRUE)
cluster_cat = kmeans(twitter.scaled, centers = 10, n=50)
qplot(religion, sports_fandom, data=twitter.data, color=factor(cluster_cat$cluster))
qplot(parenting, family, data=twitter.data, color=factor(cluster_cat$cluster))
plotcluster(twitter.scaled, cluster_cat$cluster)
table(cluster_cat)
summary(cluster_cat)
cluster[7]
cluster$cluster
cluster_cat$cluster
str(cluster_cat$cluster)
summary(cluster_cat$cluster)
table(cluster_cat$cluster)
cluster_cat[cluster_cat$cluster==7]
cluster_cat$cluster[7]
colnames(cluster_cat)
colnames(cluster_cat$cluster)
qplot(religion, sports_fandom, data=twitter.scaled, color=factor(cluster_cat$cluster))
matrix(0)
data.frame(matrix(0))
qplot(religion, sports_fandom, data=data.frame(twitter.scaled), color=factor(cluster_cat$cluster))
table(cluster_cat$cluster)
cluster_cat[cluster]
cluster_cat[cluster_cat$cluster==7]
cluster_cat[cluster_cat$cluster=='7']
twitter_distance_matrix = dist(twitter.scaled, method='euclidean')
hier.twitter = hclust(twitter_distance_matrix, method='ward.D')
plot(hier.twitter)
cluster4 = cutree(hier.twitter, k=4)
summary(factor(cluster4))
which(cluster4 == 1)
which(cluster4 == 2)
which(cluster4 == 3)
which(cluster4 == 4)
twitter.data[which(cluster4 == 1)]
twitter.data[which(cluster4 == 1),]
plot(cluster4)
cluster_cat = kmeans(twitter.scaled, centers = 2, n=50)
qplot(scores[,1], scores[,2], color=cluster_cat$cluster, xlab='Component 1', ylab='Component 2')
pc.twitter = prcomp(twitter.scaled, scale=TRUE)
loadings = pc.twitter$rotation
scores = pc.twitter$x
# COLOR BY K-MEANS CLUSTER
qplot(scores[,1], scores[,2], color=cluster_cat$cluster, xlab='Component 1', ylab='Component 2')
cluster_cat = kmeans(twitter.scaled, centers = 10, n=50)
qplot(scores[,1], scores[,2], color=cluster_cat$cluster, xlab='Component 1', ylab='Component 2')
qplot(scores[,1], scores[,3], color=cluster_cat$cluster, xlab='Component 1', ylab='Component 2')
cluster_cat = kmeans(twitter.scaled, centers = 2, n=50)
qplot(scores[,1], color=cluster_cat$cluster, xlab='Component 1', ylab='Component 2')
scores[,2],
qplot(scores[,1], scores[,2], color=cluster_cat$cluster, xlab='Component 1', ylab='Component 2')
cluster_cat = kmeans(twitter.scaled, centers = 3, n=50)
qplot(scores[,1], scores[,2], color=cluster_cat$cluster, xlab='Component 1', ylab='Component 2')
cluster_cat = kmeans(twitter.scaled, centers = 4, n=50)
qplot(scores[,1], scores[,2], color=cluster_cat$cluster, xlab='Component 1', ylab='Component 2')
cluster_cat = kmeans(twitter.scaled, centers = 5, n=50)
qplot(scores[,1], scores[,2], color=cluster_cat$cluster, xlab='Component 1', ylab='Component 2')
o1 = order(loadings[,1])
colnames(twitter.scaled)[head(o1,10)]
colnames(twitter.scaled)[tail(o1,10)]
o2 = order(loadings[,2])
colnames(twitter.scaled)[head(o2,10)]
colnames(twitter.scaled)[tail(o2,10)]
colnames(twitter.scaled)[head(o1,15)]
colnames(twitter.scaled)[tail(o1,15)]
o2 = order(loadings[,2])
colnames(twitter.scaled)[head(o2,15)]
colnames(twitter.scaled)[tail(o2,15)]
cluster_cat = kmeans(twitter.scaled, centers = 4, n=50)
qplot(scores[,1], scores[,2], color=cluster_cat$cluster, xlab='Component 1', ylab='Component 2')
?kmeans
rm(list=ls())
library(mosaic)
library(fImport)
library(foreach)
# Import a few stocks
mystocks = c("MRK", "JNJ", "SPY")
myprices = yahooSeries(mystocks, from='2011-01-01', to='2015-07-30')
# The first few rows
head(myprices)
YahooPricesToReturns = function(series) {
mycols = grep('Adj.Close', colnames(series))
closingprice = series[,mycols]
N = nrow(closingprice)
percentreturn = as.data.frame(closingprice[2:N,]) / as.data.frame(closingprice[1:(N-1),]) - 1
mynames = strsplit(colnames(percentreturn), '.', fixed=TRUE)
mynames = lapply(mynames, function(x) return(paste0(x[1], ".PctReturn")))
colnames(percentreturn) = mynames
as.matrix(na.omit(percentreturn))
}
myreturns = YahooPricesToReturns(myprices)
# These returns can be viewed as draws from the joint distribution
pairs(myreturns)
plot(myreturns[,1], type='l')
# Look at the market returns over time
plot(myreturns[,3], type='l')
# An autocorrelation plot: nothing there
acf(myreturns[,3])
# The sample correlation matrix
cor(myreturns)
str(myreturns)
lm_MRK = lm(myreturns[,1] ~ myreturns[,4])
lm_MRK = lm(myreturns[,1] ~ myreturns[,3])
lm_JNJ = lm(myreturns[,2] ~ myreturns[,3])
coef(lm_MRK); coef(lm_JNJ)
myresiduals = cbind(resid(lm_ORCL), resid(lm_MRK), resid(lm_JNJ))
myresiduals = cbind(resid(lm_MRK), resid(lm_JNJ))
cor(myresiduals)
rm(list=ls())
mystocks = c("SPY", "TLT", "LQD", "EEM", "VNQ")
myprices = yahooSeries(mystocks, from='2010-08-05', to='2015-08-05')
YahooPricesToReturns = function(series) {
mycols = grep('Adj.Close', colnames(series))
closingprice = series[,mycols]
N = nrow(closingprice)
percentreturn = as.data.frame(closingprice[2:N,]) / as.data.frame(closingprice[1:(N-1),]) - 1
mynames = strsplit(colnames(percentreturn), '.', fixed=TRUE)
mynames = lapply(mynames, function(x) return(paste0(x[1], ".PctReturn")))
colnames(percentreturn) = mynames
as.matrix(na.omit(percentreturn))
}
myreturns = YahooPricesToReturns(myprices)
myexpected = mean(myreturns)
myexpected
myexpected = lapply(myreturns, mean)
myexpected
myexpected = c(mean(myreturns[,1]),
mean(myreturns[,2]),
mean(myreturns[,3]),
mean(myreturns[,4]),
mean(myreturns[,5]))
myexpected
mybetas = c((myexpected[1]-myexpected[2])/(myexpected[1]-myexpected[2])),
(myexpected[2]-myexpected[2])/(myexpected[1]-myexpected[2])),
(myexpected[3]-myexpected[2])/(myexpected[1]-myexpected[2])),
(myexpected[4]-myexpected[2])/(myexpected[1]-myexpected[2])),
(myexpected[5]-myexpected[2])/(myexpected[1]-myexpected[2])))
mybetas = c((myexpected[1]-myexpected[2])/(myexpected[1]-myexpected[2]),
(myexpected[2]-myexpected[2])/(myexpected[1]-myexpected[2]),
(myexpected[3]-myexpected[2])/(myexpected[1]-myexpected[2]),
(myexpected[4]-myexpected[2])/(myexpected[1]-myexpected[2]),
(myexpected[5]-myexpected[2])/(myexpected[1]-myexpected[2]))
mybetas
rep(0, 5)
?data.frame
?cbind
data.frame(0, 4, 5)
?cov
cov(myreturns[,1], myreturns[,2])
myexcess = sapply(myreturns, function(x) return(x - riskfree))
riskfree = myexpected[2]
myexcess = sapply(myreturns, function(x) return(x - riskfree))
head(myexcess)
riskfree
summary(myexcess)
class(myreturns)
myexcess = outer(1:nrow(myreturns), 1:ncol(myreturns),
function(x) return(x - riskfree))
myexcess = outer(1:nrow(myreturns), 1:ncol(myreturns),
function(x,y) return(myreturns[x,y]-riskfree))
myexcess = matrix(0, 1:nrow(myreturns), 1:ncol(myreturns))
dim(myreturns)
dim(myexcess)
myexcess = matrix(0, nrow(myreturns), ncol(myreturns))
dim(myexcess)
for(i in 1:nrow(myreturns)) {
for (j in 1:ncol(myreturns)) {
myexcess[i,j] = myreturns[i,j] - riskfree
}
}
lm.1 = lm(myexcess[,1]~myexcess[,1])
lm.1 = lm(myexcess[,1]~myexcess[,2])
summary(lm.1)
mybetas = cov(myexcess[,3], myexcess[,1])/var(myexcess[,1])
mybetas
lm.1 = lm(myexcess[,3]~myexcess[,1])
summary(lm.1)
mybeta2 = cov(myexcess[,2], myexcess[,1])/var(myexcess[,1])
mybeta2
mybeta3 = cov(myexcess[,3], myexcess[,1])/var(myexcess[,1])
mybeta3
mybeta4 = cov(myexcess[,4], myexcess[,1])/var(myexcess[,1])
mybeta4
mybeta5 = cov(myexcess[,5], myexcess[,1])/var(myexcess[,1])
mybeta5
read.csv('social_marketing.csv', header=TRUE)
twitter.data = twitter.data[,2:37]
twitter.scaled = scale(twitter.data, center=TRUE, scale=TRUE)
twitter.data = read.csv('social_marketing.csv', header=TRUE)
twitter.data = twitter.data[,2:37]
twitter.scaled = scale(twitter.data, center=TRUE, scale=TRUE)
cluster_cat = kmeans(twitter.scaled, centers = 2, n=50)
cluster_cat$centers
cluster_cat = kmeans(twitter.scaled, centers = 3, n=50)
cluster_cat$centers
cluster_cat = kmeans(twitter.scaled, centers = 4, n=50)
cluster_cat$centers
